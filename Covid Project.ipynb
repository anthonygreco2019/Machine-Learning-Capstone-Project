{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/anthony.greco/OneDrive - sv-sb.org/Data Analysis Training/Covid_Project.csv\")\n",
    "\n",
    "# Set display options for scrolling through the dataframe\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "window_categories = ['0-2', '2-4', '4-6', '6-12', 'ABOVE_12']\n",
    "oencW = OrdinalEncoder(categories=[window_categories])\n",
    "df['WINDOW'] = oencW.fit_transform(df[['WINDOW']])\n",
    "\n",
    "age_categories = [\"10th\", \"20th\", \"30th\", \"40th\", \"50th\", \"60th\", \"70th\", \"80th\", \"90th\", \"Above 90th\"]\n",
    "oencA = OrdinalEncoder(categories=[age_categories])\n",
    "df['AGE_PERCENTIL'] = oencA.fit_transform(df[['AGE_PERCENTIL']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset: Null values seem to decrease as the patient's hospital stay lengthens.\n",
    "corr_matrix = df.corr()['ICU']\n",
    "corr_matrix = pd.DataFrame(corr_matrix)\n",
    "corr_matrix['y'] = abs(corr_matrix['ICU'])\n",
    "corr_matrix = corr_matrix.sort_values(by=['ICU'])\n",
    "not_selected_features = corr_matrix[corr_matrix['ICU'] < 0.004].drop(['ICU'], axis=1)\n",
    "\n",
    "print(corr_matrix)\n",
    "print(not_selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most influential features\n",
    "# RESPIRATORY_RATE_MAX, BLOODPRESSURE_SISTOLIC_DIFF, RESPIRATORY_RATE_DIFF, BLOODPRESSURE_SISTOLIC_DIFF_REL, RESPIRATORY_RATE_DIFF_REL\n",
    "\n",
    "so.Plot(df, x=\"WINDOW\", color=\"ICU\").add(so.Bar(), so.Count(), so.Stack())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most influential features\n",
    "# RESPIRATORY_RATE_MAX, BLOODPRESSURE_SISTOLIC_DIFF, RESPIRATORY_RATE_DIFF, BLOODPRESSURE_SISTOLIC_DIFF_REL, RESPIRATORY_RATE_DIFF_REL\n",
    "\n",
    "so.Plot(df, x=\"WINDOW\", color=\"ICU\").add(so.Bar(), so.Count(), so.Stack())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify patients who did not go to the ICU by the fifth window.\n",
    "dfw_1 = df[df['WINDOW'] == 1]\n",
    "print(dfw_1.shape, dfw_1.isna().sum())\n",
    "\n",
    "# Use null values to predict ICU admission in window 1. Can we predict who will go home based on this data?\n",
    "dfw_1 = dfw_1.dropna()\n",
    "print(dfw_1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore windows 2 to 5\n",
    "dfw_2 = df[df['WINDOW'] == 2]\n",
    "dfw_3 = df[df['WINDOW'] == 3]\n",
    "dfw_4 = df[df['WINDOW'] == 4]\n",
    "dfw_5 = df[df['WINDOW'] == 5]\n",
    "\n",
    "# Number of null values\n",
    "print(dfw_2.shape, dfw_2.isna().sum())\n",
    "print(dfw_3.shape, dfw_3.isna().sum())\n",
    "print(dfw_4.shape, dfw_4.isna().sum())\n",
    "print(dfw_5.shape, dfw_5.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values by backfilling and forward-filling\n",
    "df.set_index('PATIENT_VISIT_IDENTIFIER', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Check for null values and data types\n",
    "print(df.isna().sum())\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test a decision tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df[\"ICU\"]\n",
    "X = df.drop(columns=[\"ICU\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test a decision tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = df[\"ICU\"]\n",
    "X = df.drop(columns=[\"ICU\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with GridSearchCV\n",
    "from sklearn import decomposition, tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "dec_tree = tree.DecisionTreeClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc), ('pca', pca), ('dec_tree', dec_tree)])\n",
    "\n",
    "n_components = list(range(1, X.shape[1] + 1, 1))\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2, 4, 6, 8, 10, 12]\n",
    "parameters = dict(pca__n_components=n_components, dec_tree__criterion=criterion, dec_tree__max_depth=max_depth)\n",
    "\n",
    "clf_GS = GridSearchCV(pipe, parameters)\n",
    "clf_GS.fit(X, y)\n",
    "\n",
    "# Best parameters\n",
    "print('Best Criterion:', clf_GS.best_estimator_.get_params()['dec_tree__criterion'])\n",
    "print('Best max_depth:', clf_GS.best_estimator_.get_params()['dec_tree__max_depth'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "print(); print(clf_GS.best_estimator_.get_params()['dec_tree'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
